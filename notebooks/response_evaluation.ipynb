{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90fecfbb",
   "metadata": {},
   "source": [
    "# Computing metrics on generated responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc211952",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "root_dir = Path.cwd().parent\n",
    "data_dir = root_dir / \"data\"\n",
    "OUTPUT_FILE = data_dir / \"output_ift.jsonl\"\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4092d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### utils\n",
    "\n",
    "def read_jsonl(file_path):\n",
    "    data = []\n",
    "    with open(file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            data.append(json.loads(line.strip()))\n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf7f55f6",
   "metadata": {},
   "source": [
    "### compute `repetition_ratio`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b7a760",
   "metadata": {},
   "outputs": [],
   "source": [
    "def repetition_ratio(response, n=3) -> float:\n",
    "    \"\"\"\n",
    "    Calculate the repetition ratio of words in a response.\n",
    "    \n",
    "    Args:\n",
    "        response (str): The generated response text.\n",
    "        n (int): n-gram size to consider for repetition; default=3.\n",
    "        \n",
    "    Returns:\n",
    "        float: Ratio of repeated words to total words in response\n",
    "    \"\"\"\n",
    "    tokens = word_tokenize(response.lower())\n",
    "    \n",
    "    ngrams = list(nltk.ngrams(tokens, n))\n",
    "    total_ngrams = len(ngrams)\n",
    "    unique_ngrams = len(set(ngrams))\n",
    "\n",
    "    rr = 1 - (unique_ngrams / total_ngrams) if total_ngrams > 0 else 0.0\n",
    "    return rr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7a1be3",
   "metadata": {},
   "source": [
    "### compute `self_bleu`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec24224",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "\n",
    "def self_bleu(responses: list[str]) -> float:\n",
    "    \"\"\"\n",
    "    calculate self-BLEU across responses.\n",
    "    \n",
    "    Args:\n",
    "        responses: List of response texts\n",
    "    \n",
    "    Returns:\n",
    "        avg self-BLEU score (0-1, lower = more diverse)\n",
    "    \"\"\"\n",
    "    if len(responses) < 2:\n",
    "        return 0.0\n",
    "    \n",
    "    smoothing = SmoothingFunction()\n",
    "    scores = []\n",
    "    \n",
    "    for i, response in enumerate(responses):\n",
    "        hypothesis = word_tokenize(response.lower())\n",
    "        references = [\n",
    "            word_tokenize(responses[j].lower()) \n",
    "            for j in range(len(responses)) if j != i\n",
    "        ]\n",
    "        \n",
    "        score = sentence_bleu(\n",
    "            references,\n",
    "            hypothesis,\n",
    "            smoothing_function=smoothing.method1\n",
    "        )\n",
    "        scores.append(score)\n",
    "    \n",
    "    return sum(scores) / len(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb1650a",
   "metadata": {},
   "source": [
    "### aggregate and visualise results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a1cbf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute rr for each response in the output file per model per prompt_id\n",
    "\n",
    "# dict to store results grouped by n-gram size, model, and profile_id\n",
    "results = {}\n",
    "\n",
    "# load data at once\n",
    "data_list = []\n",
    "models = set()\n",
    "with open(OUTPUT_FILE, 'r') as f:\n",
    "    for line in f:\n",
    "        data_list.append(json.loads(line.strip()))\n",
    "        models.add(data_list[-1]['model'])\n",
    "\n",
    "# loop through models\n",
    "for model in models:\n",
    "\n",
    "####################3\n",
    "# loop through n-gram sizes\n",
    "for n in [1, 2, 3, 4]:\n",
    "    results[n] = {}\n",
    "    \n",
    "    for data in data_list:\n",
    "        profile_id = data['profile_id']\n",
    "        response_number = data['response_number']\n",
    "        response = data['response']\n",
    "        \n",
    "        # create nested dictionary structure if not there\n",
    "        if model not in results[n]:\n",
    "            results[n][profile_id] = {}\n",
    "        \n",
    "        # calculate rr for this response with current n\n",
    "        rr = repetition_ratio(response, n=n)\n",
    "        results[n][profile_id][response_number] = rr\n",
    "\n",
    "# Print results organized by n-gram size, model, and profile_id\n",
    "for n in [1, 2, 3, 4]:\n",
    "    print(f\"\\n{'#' * 80}\")\n",
    "    print(f\"N-GRAM SIZE: {n}\")\n",
    "    print(f\"{'#' * 80}\")\n",
    "    \n",
    "    for model, profiles in results[n].items():\n",
    "        print(f\"\\nModel: {model}\")\n",
    "        print(\"=\" * 80)\n",
    "\n",
    "        # for a given profile_id, print each response's rr and average rr\n",
    "        for profile_id, responses in profiles.items():\n",
    "            print(f\"\\n  Profile ID: {profile_id}\")\n",
    "            total_rr = 0\n",
    "            \n",
    "            # compute average rr for this profile_id\n",
    "            for response_num in sorted(responses.keys()):\n",
    "                rr = responses[response_num]\n",
    "                total_rr += rr\n",
    "                print(f\"    Response {response_num}: {rr:.4f}\")\n",
    "            avg_rr = total_rr / len(responses)\n",
    "            print(f\"    Average: {avg_rr:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
